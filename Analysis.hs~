module Analysis
    (
	--cShift
	nchr
	, nord
	, nAlphabet
--	, alphabet
--	, clean
	, count2freq
	, txt2count
	, kapa
	, corr
	, scorr
	, target
	, Analysis.toUpper
	, Analysis.toLower
	, engFreq
	, engMap
	, hamming
--	, splitIC
--	, ixOfMin
--	, ixOfMax
--	, splitText
--	, corr
--	, isUpperChar
--	, affineShift
--	, affineDeshift
--	, modinv
    ) where

import System.IO
import Control.Monad
import Data.Array as A
import Data.Char as C
import Data.Word
import Data.Maybe
import Data.Monoid
import Data.Map as M
import Data.List as L
import Text.Printf
import Data.Tuple (swap)
import Data.ByteString as B

import Data.ByteString.Internal (c2w, w2c)
--import Data.ByteString.Char8 (pack)
--import GHC.Word (Word8)


hamming :: String -> String -> Int
hamming xs ys = L.length (L.filter not (L.zipWith (==) xs ys))

bhamming :: ByteString -> ByteString -> Int
bhamming = undefined
--bhamming xs ys = B.length (B.filter not (B.zipWith (==) xs ys))

-- Counts of the letters in a text
data  ICount = ICount (Map Word8 Int) deriving (Show)
data  DCount = DCount (Map Word8 Double) deriving (Show)

zeroCount::ICount
zeroCount = ICount $ fromList $ Prelude.map (\x->(nchr x,0)) [0..nAlphabet]

-- A monoid instance where zero is alphabet with 0 frequencies
instance Monoid ICount where
    mempty = zeroCount
    mappend (ICount c) (ICount d) = ICount $ M.union c d

-- insert a character into a map of characters
-- Increment the count by 1
cInsert::ICount->Word8->ICount
cInsert (ICount m) c = if (ord $ w2c c)>64 && (ord $ w2c c)<91 then ICount $ insertWith (+) c 1 m else ICount $ insertWith (+) (c2w '~') 1 m
--cInsert (ICount m) c = if (ord $ w2c c)>64 && (ord $ w2c c)<91 then ICount $ insertWith (+) c 1 m else ICount m

-- counts the occurences of each character in a string
txt2count::ByteString->ICount
txt2count txt = B.foldl cInsert zeroCount txt

-- converts the count into a frequency
count2freq::ICount->DCount
count2freq (ICount c) = DCount $ M.map (\v-> fromIntegral v / fromIntegral tot ) c
        where
            tot = M.foldl (+) 0 c

-- Works out the incidence of coincidence
-- IC = sum{ f_i*(f_i-1)}/N/(N-1)*n
-- where N = length of the text (= sum of the f_i)
-- n = the size of the alphabet
-- f_i = the frequency of letter i
kapa::ICount->Double
kapa (ICount fs) = (M.foldlWithKey (\a k f -> (fromIntegral $ f*(f-1))+a) (0.0) fs) / (fromIntegral $ tot * (tot - 1)) * fromIntegral nAlphabet
        where
            tot = M.foldl (+) 0 fs

corr::ICount->Double
corr (ICount fs) = M.foldl (+) 0.0 $ M.intersectionWith (\f l -> (fromIntegral f)*l) fs engMap

-- Calculates the letter where 0 gives 'A'
nchr::Int->Word8
nchr i = c2w $ chr $ ord 'A' + i

-- Calculates ord where ord 'A'=0 etc.
nord::Word8->Int
nord c = ord (w2c c) - ord 'A'

nAlphabet = 26::Int


toLower :: ByteString -> ByteString
toLower bs = B.map (\w -> c2w $ C.toLower $ w2c w) bs

toUpper :: ByteString -> ByteString
toUpper bs = B.map (\w -> c2w $ C.toUpper $ w2c w) bs


{-
-- Cleans cipher text of everything except alphabetic characters
clean::(Word8->Bool)->[Word8]->[Word8]
clean _ [] = []
clean f (x:xs) = case f x of
			True -> x:(clean f xs)
			False-> clean f xs

isUpperChar::Word8->Bool
isUpperChar x = (nord x >= 0) && (nord x <26)



-- The number of letters in the alphabet
-- alphabet = "ABCDEFGHIJLMNOPQRSTUVWXYZ"

-- Shifts right according to an alphabet with nAlphabet Chars
cShift::Word8->Word8->Word8
cShift k c = nchr $ mod (nord k + nord c) nAlphabet

  
-- Switches a->z, b->y etc (when n=26)
reverseTxt::ByteString->ByteString       
-- reverseTxt txt = L.map (\c-> chr $ nAlphabet - ord c + 65) txt     
reverseTxt txt = B.pack $ L.map (\c-> c2w $ chr $ nAlphabet - 1 + 2*65 - (ord $ w2c c)) $ B.unpack txt     
            
-- works out the ic of a string split into n pieces (ie. autocorrelation)
splitIC::Int->ByteString->Double
splitIC n txt = (sum $ L.map (ic.txt2count) spl)/(fromIntegral n)
        where
            spl = splitText n txt
            
-- split a list into n bits alternating which bit to put the next item in
splitText::Int->[a]->[[a]]
splitText _ [] = []
splitText 1 xs = [xs]
splitText n xs = A.elems $ split' 0 n init xs
            where
                init::Array Int [a]
                init = listArray (0,n-1) $ B.replicate n ([])

split'::Int->Int->Array Int [a]->[a]->Array Int [a]
split' i n acc [] = acc
split' i n acc (x:xs) = split' (mod (i+1) n) n (accum (++) acc [(i, [x])]) xs

-- Index of the minimum starting with 0
ixOfMin::Ord a=>[a]->Int
ixOfMin xs = fromJust $ B.elemIndex (B.minimum xs) xs

-- Index of the minimum starting with 0
ixOfMax::Ord a=>[a]->Int
ixOfMax xs = fromJust $ B.elemIndex (B.maximum xs) xs

-- Shift a character by an int
cshift::Char->Char->Char
cshift k ' ' = ' '
cshift k c = chr $ (ord 'A') + (mod (ord k + ord c - ord 'A' - ord 'A') nAlphabet)

-- Shift a char x to a*x+b mod 26
affineShift::Int->Int->Char->Char
affineShift a b x = nchr $ mod ((a*nord x) + b) nAlphabet

-- Shift a char x to a*x+b mod 26
affineDeshift::Int->Int->Char->Char
affineDeshift a b x = nchr $ mod (inva*(nord x - b)) nAlphabet
	where
		inva = modinv nAlphabet a
-}

-- Works out the correlation of an offset of n of a string with standard
-- english text frequencies
scorr::ByteString->Double
scorr pt = M.foldr (+) 0.0 $ M.intersectionWith (\a b -> a*b) ptMap engMap
    where
        ptCount = count2freq $ txt2count pt
        count2map (DCount m) = m
        ptMap = count2map ptCount
  
 {-          
-- Works out an inverse of x in mod s
modinv::(Num t, Ord t, Integral t) => t->t->t
modinv s x = B.head $ L.filter (\z-> ((mod (z*x) s)==1)) [0..(s-1)]

-}

-- These are the frequencies of English text by letter        
engFreq::[(Word8, Double)]
engFreq = [ (c2w 'A', 0.08167)
        ,(c2w 'B',0.01492)
        ,(c2w 'C',0.02782)
        ,(c2w 'D',0.04253)
        ,(c2w 'E',0.12702)
        ,(c2w 'F',0.02228)
        ,(c2w 'G',0.02015)
        ,(c2w 'H',0.06094)
        ,(c2w 'I',0.06966)	
        ,(c2w 'J',0.00153)
        ,(c2w 'K',0.00772)	
        ,(c2w 'L',0.04025)	
        ,(c2w 'M',0.02406)	
        ,(c2w 'N',0.06749)	
        ,(c2w 'O',0.07507)	
        ,(c2w 'P',0.01929)	
        ,(c2w 'Q',0.00095)	
        ,(c2w 'R',0.05987)	
        ,(c2w 'S',0.06327)	
        ,(c2w 'T',0.09056)	
        ,(c2w 'U',0.02758)	
        ,(c2w 'V',0.00978)	
        ,(c2w 'W',0.02360)	
        ,(c2w 'X',0.00150)	
        ,(c2w 'Y',0.01974)	 
        ,(c2w 'Z',0.00074)]
                  
engMap = L.foldl (\m f -> M.insert (fst f) (snd f) m) M.empty engFreq                  
                  
target::Double
target = (L.sum $ L.map (\x->(snd x)*(snd x)) engFreq)*(fromIntegral $ L.length engFreq)

bigramFreq = [("TH",0.03880),
	("HE",0.03680),
	("IN",0.02280),
	("ER",0.02180),
	("AN",0.02140),
	("RE",0.01750),
	("ND",0.01570),
	("AT",0.01420),
	("ON",0.01380),
	("NT",0.01340),
	("HA",0.01290),
	("ES",0.01280),
	("ST",0.01270),
	("EN",0.01170),
	("ED",0.01150),
	("TO",0.01135),
	("IT",0.01110),
	("OU",0.01090),
	("EA",0.01090),
	("HI",0.01050)]

trigramFreq = [("THE",0.03508232)
	, ("AND",0.01593878)
	, ("ING",0.01147042)
	, ("HER",0.00822444)
	, ("HAT",0.00650715)
	, ("HIS",0.00596748)
	, ("THA",0.00593593)
	, ("ERE",0.00560594)
	, ("FOR",0.00555372)
	, ("ENT",0.00530771)
	, ("ION",0.00506454)
	, ("TER",0.00461099)
	, ("WAS",0.00460487)
	, ("YOU",0.00437213)
	, ("ITH",0.00431250)
	, ("VER",0.00430732)
	, ("ALL",0.00422758)
	, ("WIT",0.00397290)
	, ("THI",0.00394796)
	, ("TIO",0.00378058)]


quadrigramFreq = [("THAT",0.00761242)
	,("THER",0.00604501)
	,("WITH",0.00573866)
	,("TION",0.00551919)
	,("HERE",0.00374549)
	,("OULD",0.00369920)
	,("IGHT",0.00309440)
	,("HAVE",0.00290544)
	,("HICH",0.00284292)
	,("WHIC",0.00283826)
	,("THIS",0.00276333)
	,("THIN",0.00270413)
	,("THEY",0.00262421)
	,("ATIO",0.00262386)
	,("EVER",0.00260695)
	,("FROM",0.00258580)
	,("OUGH",0.00253447)
	,("WERE",0.00231089)
	,("HING",0.00229944)
	,("MENT",0.00223347)]


acsiiFreq = [

(' ', 0.171662) 
(! 170 ( 0.0072%) 
(" 5,804 ( 0.2442%) 
35 # 425 ( 0.0179%) 
36 $ 1,333 ( 0.0561%) 
37 % 380 ( 0.0160%) 
38 & 536 ( 0.0226%) 
39 ' 5,816 ( 0.2447%) 
40 ( 5,176 ( 0.2178%) 
41 ) 5,307 ( 0.2233%) 
42 * 1,493 ( 0.0628%) 
43 + 511 ( 0.0215%) 
44 , 17,546 ( 0.7384%) 
45 - 32,638 ( 1.3734%) 
46 . 35,940 ( 1.5124%) 
47 / 3,681 ( 0.1549%) 
48 0 13,109 ( 0.5516%) 
49 1 10,916 ( 0.4594%) 
50 2 7,894 ( 0.3322%) 
51 3 4,389 ( 0.1847%) 
52 4 3,204 ( 0.1348%) 
53 5 3,951 ( 0.1663%) 
54 6 2,739 ( 0.1153%) 
55 7 2,448 ( 0.1030%) 
56 8 2,505 ( 0.1054%) 
57 9 2,433 ( 0.1024%) 
58 : 10,347 ( 0.4354%) 
59 ; 2,884 ( 0.1214%) 
60 < 2,911 ( 0.1225%) 
61 = 540 ( 0.0227%) 
62 > 2,952 ( 0.1242%) 
63 ? 3,503 ( 0.1474%) 
64 @ 173 ( 0.0073%) 
65 A 7,444 ( 0.3132%) 
66 B 5,140 ( 0.2163%) 
67 C 9,283 ( 0.3906%) 
68 D 7,489 ( 0.3151%) 
69 E 6,351 ( 0.2673%) 
70 F 3,365 ( 0.1416%) 
71 G 4,459 ( 0.1876%) 
72 H 5,515 ( 0.2321%) 
73 I 7,631 ( 0.3211%) 
74 J 4,102 ( 0.1726%) 
75 K 1,633 ( 0.0687%) 
76 L 4,476 ( 0.1884%) 
77 M 8,386 ( 0.3529%) 
78 N 4,954 ( 0.2085%) 
79 O 4,378 ( 0.1842%) 
80 P 6,211 ( 0.2614%) 
81 Q 751 ( 0.0316%) 
82 R 5,986 ( 0.2519%) 
83 S 9,512 ( 0.4003%) 
84 T 7,895 ( 0.3322%) 
85 U 1,934 ( 0.0814%) 
86 V 2,119 ( 0.0892%) 
87 W 6,005 ( 0.2527%) 
88 X 815 ( 0.0343%) 
89 Y 722 ( 0.0304%) 
90 Z 180 ( 0.0076%) 
91 [ 205 ( 0.0086%) 
92 \ 37 ( 0.0016%) 
93 ] 210 ( 0.0088%) 
94 ^ 8 ( 0.0003%) 
95 _ 2,755 ( 0.1159%) 
96 ` 21 ( 0.0009%) 
97 a 123,287 ( 5.1880%) 
98 b 24,227 ( 1.0195%) 
99 c 50,211 ( 2.1129%) 
100 d 59,577 ( 2.5071%) 
101 e 203,824 ( 8.5771%) 
102 f 32,616 ( 1.3725%) 
103 g 37,064 ( 1.5597%) 
104 h 65,217 ( 2.7444%) 
105 i 116,488 ( 4.9019%) 
106 j 2,061 ( 0.0867%) 
107 k 16,047 ( 0.6753%) 
108 l 75,450 ( 3.1750%) 
109 m 39,060 ( 1.6437%) 
110 n 118,108 ( 4.9701%) 
111 o 137,119 ( 5.7701%) 
112 p 36,791 ( 1.5482%) 
113 q 1,774 ( 0.0747%) 
114 r 101,201 ( 4.2586%) 
115 s 103,814 ( 4.3686%) 
116 t 151,376 ( 6.3700%) 
117 u 49,901 ( 2.0999%) 
118 v 20,109 ( 0.8462%) 
119 w 30,974 ( 1.3034%) 
120 x 4,635 ( 0.1950%) 
121 y 26,924 ( 1.1330%) 
122 z 1,417 ( 0.0596%) 
123 { 62 ( 0.0026%) 
124 | 16 ( 0.0007%) 
125 } 61 ( 0.0026%) 
126 ~ 8 ( 0.0003%) 
131 ƒ 1 ( 0.0000%) 
149 • 15,233 ( 0.6410%) 
183 · 23 ( 0.0010%) 
223 ß 1 ( 0.0000%) 
226 â 1 ( 0.0000%) 
229 å 1 ( 0.0000%) 
230 æ 1 ( 0.0000%) 
237 í 1 ( 0.0000%) 


